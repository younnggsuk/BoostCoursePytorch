{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression\n",
    "\n",
    "다변량 선형 회귀를 구현해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 직접 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70],])\n",
    "y_train = torch.FloatTensor([[152],\n",
    "                             [185],\n",
    "                             [180],\n",
    "                             [196],\n",
    "                             [142]])\n",
    "\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20, H: [0. 0. 0. 0. 0.], Loss: 29661.801\n",
      "Epoch    2/20, H: [67.25779  80.839676 79.65228  86.73937  61.6605  ], Loss: 9298.521\n",
      "Epoch    3/20, H: [104.91277  126.098976 124.24662  135.30151   96.18212 ], Loss: 2915.712\n",
      "Epoch    4/20, H: [125.994225 151.43813  149.21329  162.48962  115.509705], Loss: 915.041\n",
      "Epoch    5/20, H: [137.79674 165.62471 163.19115 177.71118 126.33068], Loss: 287.936\n",
      "Epoch    6/20, H: [144.40439 173.56741 171.0168  186.23315 132.38913], Loss: 91.371\n",
      "Epoch    7/20, H: [148.10355 178.01434 175.39803 191.00421 135.7812 ], Loss: 29.758\n",
      "Epoch    8/20, H: [150.1744  180.50417 177.85086 193.67534 137.6805 ], Loss: 10.445\n",
      "Epoch    9/20, H: [151.33357 181.89825 179.22404 195.17072 138.74402], Loss: 4.391\n",
      "Epoch   10/20, H: [151.98238 182.6789  179.99278 196.00789 139.33961], Loss: 2.493\n",
      "Epoch   11/20, H: [152.34541 183.11606 180.42313 196.47653 139.67325], Loss: 1.898\n",
      "Epoch   12/20, H: [152.54848 183.36095 180.66399 196.73888 139.86023], Loss: 1.711\n",
      "Epoch   13/20, H: [152.662   183.4982  180.7988  196.88571 139.96509], Loss: 1.651\n",
      "Epoch   14/20, H: [152.72534 183.57516 180.8742  196.96783 140.02399], Loss: 1.632\n",
      "Epoch   15/20, H: [152.76062 183.61838 180.91635 197.01378 140.05713], Loss: 1.626\n",
      "Epoch   16/20, H: [152.78018 183.64272 180.93991 197.03946 140.07587], Loss: 1.623\n",
      "Epoch   17/20, H: [152.79094 183.65648 180.95305 197.05379 140.08653], Loss: 1.622\n",
      "Epoch   18/20, H: [152.79677 183.66429 180.96033 197.06175 140.0927 ], Loss: 1.621\n",
      "Epoch   19/20, H: [152.79985 183.66881 180.96436 197.06615 140.09631], Loss: 1.621\n",
      "Epoch   20/20, H: [152.80138 183.67148 180.96654 197.06856 140.09853], Loss: 1.620\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    h = torch.matmul(x_train, W)+b\n",
    "    loss = torch.mean((h-y_train)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch {:4d}/{}, H: {}, Loss: {:.3f}\".format(\n",
    "        epoch, num_epochs, torch.squeeze(h).detach().numpy(), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `nn.Module`,  `F.mse_loss`를 통해 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiVariableLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiVariableLinearRegression(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 0.3817,  0.4611, -0.3913]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3967], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model = MultiVariableLinearRegression()\n",
    "print(model)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20, predict: [35.80764  40.088326 41.11862  43.105827 31.308266], Loss: 17883.479\n",
      "Epoch    2/20, predict: [ 88.027504 102.85404  102.96206  110.45187   79.18295 ], Loss: 5607.949\n",
      "Epoch    3/20, predict: [117.263176 137.99449  137.58582  148.15639  105.98651 ], Loss: 1760.222\n",
      "Epoch    4/20, predict: [133.63084 157.66853 156.9703  169.2657  120.99311], Loss: 554.163\n",
      "Epoch    5/20, predict: [142.79419 168.68353 167.82288 181.08395 129.39503], Loss: 176.126\n",
      "Epoch    6/20, predict: [147.9241  174.85063 173.89874 187.70052 134.09924], Loss: 57.630\n",
      "Epoch    7/20, predict: [150.7958  178.30356 177.30026 191.40482 136.7332 ], Loss: 20.487\n",
      "Epoch    8/20, predict: [152.40329 180.23697 179.20459 193.47865 138.20816], Loss: 8.843\n",
      "Epoch    9/20, predict: [153.30295 181.31963 180.27065 194.63966 139.03421], Loss: 5.193\n",
      "Epoch   10/20, predict: [153.80629 181.92596 180.86739 195.28958 139.49693], Loss: 4.047\n",
      "Epoch   11/20, predict: [154.0878  182.26562 181.20137 195.65341 139.75627], Loss: 3.687\n",
      "Epoch   12/20, predict: [154.2451  182.45604 181.3883  195.85704 139.90176], Loss: 3.573\n",
      "Epoch   13/20, predict: [154.33287 182.56284 181.49283 195.97096 139.98347], Loss: 3.536\n",
      "Epoch   14/20, predict: [154.38168 182.62286 181.55127 196.03471 140.0295 ], Loss: 3.523\n",
      "Epoch   15/20, predict: [154.40868 182.65666 181.58388 196.07033 140.05554], Loss: 3.517\n",
      "Epoch   16/20, predict: [154.42351 182.67581 181.60205 196.0902  140.0704 ], Loss: 3.515\n",
      "Epoch   17/20, predict: [154.43149 182.68674 181.61212 196.10126 140.07898], Loss: 3.513\n",
      "Epoch   18/20, predict: [154.43564 182.69307 181.61766 196.10739 140.08408], Loss: 3.511\n",
      "Epoch   19/20, predict: [154.43767 182.69682 181.62067 196.11076 140.08719], Loss: 3.509\n",
      "Epoch   20/20, predict: [154.43849 182.69914 181.62227 196.1126  140.0892 ], Loss: 3.507\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    predict = model(x_train)\n",
    "    loss = F.mse_loss(predict, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch {:4d}/{}, predict: {}, Loss: {:.3f}\".format(\n",
    "        epoch, num_epochs, torch.squeeze(predict).detach().numpy(), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
