{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6EjndpfkndE"
   },
   "source": [
    "# ResNet\n",
    "\n",
    "`torchvision`에 있는 `ResNet`을 참고해서 ResNet을 직접 구현해보자!\n",
    "\n",
    "그리고 이를 cifar10 dataset에 적용해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfpvSeLUkjvH"
   },
   "source": [
    "## 1. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7333,
     "status": "ok",
     "timestamp": 1593783161129,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "xvrki4w0kTbm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7327,
     "status": "ok",
     "timestamp": 1593783161130,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "a5q5fHihkYMH"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7320,
     "status": "ok",
     "timestamp": 1593783161130,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "EPs1Zx6dkZrY"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7316,
     "status": "ok",
     "timestamp": 1593783161131,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "OvYyRqUQkasd"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7706,
     "status": "ok",
     "timestamp": 1593783161526,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "JLxr4CqM2F4F"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \n",
    "        downsample = None\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride), #conv1x1(256, 512, 2)\n",
    "                nn.BatchNorm2d(planes * block.expansion), #batchnrom2d(512)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        \n",
    "        self.inplanes = planes * block.expansion #self.inplanes = 128 * 4\n",
    "        \n",
    "        for _ in range(1, blocks): \n",
    "            layers.append(block(self.inplanes, planes)) # * 3\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7703,
     "status": "ok",
     "timestamp": 1593783161527,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "mHN0RqpL2IE-"
   },
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, **kwargs):\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs) #=> 2*(2+2+2+2) +1(conv1) +1(fc)  = 16 +2 =resnet 18\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7698,
     "status": "ok",
     "timestamp": 1593783161527,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "VwrkqOwP2JU_"
   },
   "outputs": [],
   "source": [
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #=> 3*(3+4+6+3) +(conv1) +1(fc) = 48 +2 = 50\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7695,
     "status": "ok",
     "timestamp": 1593783161528,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "yGZXm5o-2KjS"
   },
   "outputs": [],
   "source": [
    "def resnet152(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs) # 3*(3+8+36+3) +2 = 150+2 = resnet152    \n",
    "    return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omCo2WIBkeAp"
   },
   "source": [
    "## 2. CIFAR-10 Dataset\n",
    "\n",
    "앞의 VGGNet에서는 평균과 표준편차를 직접 구하지 않고 0.5라고 가정하고 `torchvision.transforms.Normalize()`를 수행하였다.\n",
    "\n",
    "하지만 여기서는 직접 train data의 평균과 표준편차를 구한 후, 정규분포화를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7690,
     "status": "ok",
     "timestamp": 1593783161528,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "_bphU6WckbeR"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7686,
     "status": "ok",
     "timestamp": 1593783161529,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "GYCIwOR7okFM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "validation_ratio = 0.2\n",
    "random_seed = 10\n",
    "initial_lr = 0.005\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9152,
     "status": "ok",
     "timestamp": 1593783163000,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "q47yPQH8kqna",
    "outputId": "48a0df4e-4941-4266-b0a4-17c496042f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10276,
     "status": "ok",
     "timestamp": 1593783164132,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "HRKp96Gh2Q2I",
    "outputId": "e4a60763-8aa0-4b09-956a-4cfc85a17334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "train_data_mean = trainset.data.mean( axis=(0,1,2) )\n",
    "train_data_std = trainset.data.std( axis=(0,1,2) )\n",
    "\n",
    "train_data_mean = train_data_mean / 255\n",
    "train_data_std = train_data_std / 255\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13128,
     "status": "ok",
     "timestamp": 1593783166992,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "MeUfDzse2RwM",
    "outputId": "6c2340f2-5cd6-4ed1-ff77-e920e13a72c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    # train data에는 image augmentation을 수행\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=True, download=True, transform=transform_train)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=True, download=True, transform=transform_test)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13124,
     "status": "ok",
     "timestamp": 1593783166994,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "R9n-nQLV2SlY"
   },
   "outputs": [],
   "source": [
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=6\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=6\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=6\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2vu8Q5l4INg"
   },
   "source": [
    "## 3. 학습\n",
    "\n",
    "ResNet50을 사용해서 학습을 수행한다.\n",
    "\n",
    "이번에는 앞의 VGG와 달리 val_loss를 비교하며 최상의 모델을 저장한 후, 이를 불러와 test에 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15694,
     "status": "ok",
     "timestamp": 1593783169571,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "NcMZcF0Akuv5"
   },
   "outputs": [],
   "source": [
    "resnet = resnet50(num_classes=10, zero_init_residual=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15691,
     "status": "ok",
     "timestamp": 1593783169572,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "SiaAB-ALlmzq"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4261686,
     "status": "ok",
     "timestamp": 1593787415573,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "DFdl3XfZlqDk",
    "outputId": "45ee2f1d-c2f8-47fc-e9d2-44bcc2cca0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch   1/30, Loss: 2.5651298\n",
      "[Valid] Epoch   1/30, Loss: 1.6872346, Accuracy: 37.5%\n",
      "[Train] Epoch   2/30, Loss: 1.5723085\n",
      "[Valid] Epoch   2/30, Loss: 1.4734730, Accuracy: 46.4%\n",
      "[Train] Epoch   3/30, Loss: 1.3886424\n",
      "[Valid] Epoch   3/30, Loss: 1.2665462, Accuracy: 54.6%\n",
      "[Train] Epoch   4/30, Loss: 1.2443051\n",
      "[Valid] Epoch   4/30, Loss: 1.1617709, Accuracy: 57.9%\n",
      "[Train] Epoch   5/30, Loss: 1.1380402\n",
      "[Valid] Epoch   5/30, Loss: 1.0614831, Accuracy: 62.2%\n",
      "[Train] Epoch   6/30, Loss: 1.0548097\n",
      "[Valid] Epoch   6/30, Loss: 1.0899091, Accuracy: 62.0%\n",
      "[Train] Epoch   7/30, Loss: 0.9880305\n",
      "[Valid] Epoch   7/30, Loss: 0.9734443, Accuracy: 65.8%\n",
      "[Train] Epoch   8/30, Loss: 0.9506536\n",
      "[Valid] Epoch   8/30, Loss: 0.9801546, Accuracy: 66.1%\n",
      "[Train] Epoch   9/30, Loss: 0.9034039\n",
      "[Valid] Epoch   9/30, Loss: 0.9201042, Accuracy: 68.6%\n",
      "[Train] Epoch  10/30, Loss: 0.8751188\n",
      "[Valid] Epoch  10/30, Loss: 0.8494295, Accuracy: 71.4%\n",
      "[Train] Epoch  11/30, Loss: 0.8527765\n",
      "[Valid] Epoch  11/30, Loss: 0.8506575, Accuracy: 70.9%\n",
      "[Train] Epoch  12/30, Loss: 0.8304979\n",
      "[Valid] Epoch  12/30, Loss: 0.8561983, Accuracy: 71.0%\n",
      "[Train] Epoch  13/30, Loss: 0.8215953\n",
      "[Valid] Epoch  13/30, Loss: 0.8797995, Accuracy: 69.6%\n",
      "[Train] Epoch  14/30, Loss: 0.8080376\n",
      "[Valid] Epoch  14/30, Loss: 0.8982151, Accuracy: 70.3%\n",
      "[Train] Epoch  15/30, Loss: 0.7941391\n",
      "[Valid] Epoch  15/30, Loss: 0.8357590, Accuracy: 72.1%\n",
      "[Train] Epoch  16/30, Loss: 0.7817112\n",
      "[Valid] Epoch  16/30, Loss: 0.9801959, Accuracy: 67.7%\n",
      "[Train] Epoch  17/30, Loss: 0.7677870\n",
      "[Valid] Epoch  17/30, Loss: 0.8123004, Accuracy: 73.3%\n",
      "[Train] Epoch  18/30, Loss: 0.7645725\n",
      "[Valid] Epoch  18/30, Loss: 0.8416758, Accuracy: 71.7%\n",
      "[Train] Epoch  19/30, Loss: 0.7545788\n",
      "[Valid] Epoch  19/30, Loss: 0.7887115, Accuracy: 72.7%\n",
      "[Train] Epoch  20/30, Loss: 0.7613044\n",
      "[Valid] Epoch  20/30, Loss: 0.9124405, Accuracy: 69.0%\n",
      "[Train] Epoch  21/30, Loss: 0.7505595\n",
      "[Valid] Epoch  21/30, Loss: 0.7733295, Accuracy: 73.5%\n",
      "[Train] Epoch  22/30, Loss: 0.7322057\n",
      "[Valid] Epoch  22/30, Loss: 0.9967261, Accuracy: 66.6%\n",
      "[Train] Epoch  23/30, Loss: 0.7262716\n",
      "[Valid] Epoch  23/30, Loss: 0.7613227, Accuracy: 73.2%\n",
      "[Train] Epoch  24/30, Loss: 0.7258264\n",
      "[Valid] Epoch  24/30, Loss: 0.7875329, Accuracy: 73.5%\n",
      "[Train] Epoch  25/30, Loss: 0.7239140\n",
      "[Valid] Epoch  25/30, Loss: 0.9941060, Accuracy: 68.0%\n",
      "[Train] Epoch  26/30, Loss: 0.7201560\n",
      "[Valid] Epoch  26/30, Loss: 0.9551010, Accuracy: 68.3%\n",
      "[Train] Epoch  27/30, Loss: 0.7069446\n",
      "[Valid] Epoch  27/30, Loss: 0.8622838, Accuracy: 71.8%\n",
      "[Train] Epoch  28/30, Loss: 0.7078912\n",
      "[Valid] Epoch  28/30, Loss: 0.7878329, Accuracy: 72.9%\n",
      "[Train] Epoch  29/30, Loss: 0.6961650\n",
      "[Valid] Epoch  29/30, Loss: 0.7887039, Accuracy: 73.9%\n",
      "[Train] Epoch  30/30, Loss: 0.6903338\n",
      "[Valid] Epoch  30/30, Loss: 0.9062790, Accuracy: 70.8%\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "min_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    running_loss = 0.0\n",
    "    resnet.train() # training mode for dropout\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running_loss += loss.item()\n",
    "        # # print every 30 mini-batches\n",
    "        # if i % 30 == 29:\n",
    "        #     print('[Train] Epoch %3d, Mini-batches %5d, Loss: %.7f' %\n",
    "        #           (epoch+1, i+1, running_loss / 30))\n",
    "        #     running_loss = 0.0\n",
    "        running_loss += loss / len(train_loader)\n",
    "\n",
    "    print('[Train] Epoch %3d/%d, Loss: %.7f' % (epoch+1, epochs, running_loss))\n",
    "    \n",
    "    # Validation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        resnet.eval() # evaluation mode for dropout\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss / len(valid_loader)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        print('[Valid] Epoch %3d/%d, Loss: %.7f, Accuracy: %.1f%%' % \n",
    "              (epoch+1, epochs, val_loss, (100*correct / total))\n",
    "            )\n",
    "        \n",
    "        # save best model\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(resnet.state_dict(), \"../models/resnet50.pth\")\n",
    "        \n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1350,
     "status": "ok",
     "timestamp": 1593787500725,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "JYWZQrnWHsA-",
    "outputId": "55d92bea-f5a3-41ac-a028-a339f092a8a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = resnet50(num_classes=10, zero_init_residual=True).to(device)\n",
    "best_model.load_state_dict(torch.load(\"../models/resnet50.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5378,
     "status": "ok",
     "timestamp": 1593787531407,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "1UEDDf4ylrWf",
    "outputId": "6d069ebc-1158-4eb9-9d41-8b7cb297a378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 73.7 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    resnet.eval() # evaluation mode for dropout\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.1f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMVMqkcrJjEu4ybkccUv80w",
   "collapsed_sections": [],
   "name": "resnet",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
