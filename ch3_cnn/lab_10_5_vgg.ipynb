{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6EjndpfkndE"
   },
   "source": [
    "# VGG\n",
    "\n",
    "`torchvision`에 있는 `VGG`를 참고해서 VGG Net을 직접 구현해보자!\n",
    "\n",
    "그리고 이를 cifar10 dataset에 적용해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfpvSeLUkjvH"
   },
   "source": [
    "## 1. VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3688,
     "status": "ok",
     "timestamp": 1593769476333,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "xvrki4w0kTbm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3685,
     "status": "ok",
     "timestamp": 1593769476334,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "a5q5fHihkYMH"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m. weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3681,
     "status": "ok",
     "timestamp": 1593769476334,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "EPs1Zx6dkZrY"
   },
   "outputs": [],
   "source": [
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3679,
     "status": "ok",
     "timestamp": 1593769476335,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "OvYyRqUQkasd"
   },
   "outputs": [],
   "source": [
    "cfg = [32,32,'M', 64,64,128,128,128,'M',256,256,256,512,512,512,'M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omCo2WIBkeAp"
   },
   "source": [
    "## 2. CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3675,
     "status": "ok",
     "timestamp": 1593769476335,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "_bphU6WckbeR"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3672,
     "status": "ok",
     "timestamp": 1593769476336,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "GYCIwOR7okFM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "validation_ratio = 0.2\n",
    "random_seed = 10\n",
    "initial_lr = 0.005\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6441,
     "status": "ok",
     "timestamp": 1593769479109,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "q47yPQH8kqna",
    "outputId": "227a8e4d-2201-45bc-81d6-218194f94bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=True, download=True, transform=transform)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=True, download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='../datasets/CIFAR10_dataset', train=False, download=True, transform=transform)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2vu8Q5l4INg"
   },
   "source": [
    "## 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11310,
     "status": "ok",
     "timestamp": 1593769483983,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "NcMZcF0Akuv5"
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG(make_layers(cfg), num_classes=num_classes, init_weights=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11310,
     "status": "ok",
     "timestamp": 1593769483986,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "SiaAB-ALlmzq"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.005, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794375,
     "status": "ok",
     "timestamp": 1593770267056,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "DFdl3XfZlqDk",
    "outputId": "e27be0d5-6215-433e-9882-097d83b1fc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch   1/30, Loss: 2.0440755\n",
      "[Valid] Epoch   1/30, Loss: 1.7301058, Accuracy: 34.8%\n",
      "[Train] Epoch   2/30, Loss: 1.5856618\n",
      "[Valid] Epoch   2/30, Loss: 1.5067730, Accuracy: 44.0%\n",
      "[Train] Epoch   3/30, Loss: 1.3876722\n",
      "[Valid] Epoch   3/30, Loss: 1.4067990, Accuracy: 51.4%\n",
      "[Train] Epoch   4/30, Loss: 1.2109097\n",
      "[Valid] Epoch   4/30, Loss: 1.1614313, Accuracy: 58.2%\n",
      "[Train] Epoch   5/30, Loss: 1.0631638\n",
      "[Valid] Epoch   5/30, Loss: 1.0294256, Accuracy: 62.8%\n",
      "[Train] Epoch   6/30, Loss: 0.9365886\n",
      "[Valid] Epoch   6/30, Loss: 0.9183221, Accuracy: 67.1%\n",
      "[Train] Epoch   7/30, Loss: 0.8514708\n",
      "[Valid] Epoch   7/30, Loss: 0.8347962, Accuracy: 70.6%\n",
      "[Train] Epoch   8/30, Loss: 0.7615770\n",
      "[Valid] Epoch   8/30, Loss: 0.7613340, Accuracy: 73.7%\n",
      "[Train] Epoch   9/30, Loss: 0.6800954\n",
      "[Valid] Epoch   9/30, Loss: 0.8201019, Accuracy: 72.0%\n",
      "[Train] Epoch  10/30, Loss: 0.6111642\n",
      "[Valid] Epoch  10/30, Loss: 0.6955789, Accuracy: 76.3%\n",
      "[Train] Epoch  11/30, Loss: 0.5522207\n",
      "[Valid] Epoch  11/30, Loss: 0.6867572, Accuracy: 76.8%\n",
      "[Train] Epoch  12/30, Loss: 0.5050203\n",
      "[Valid] Epoch  12/30, Loss: 0.6683435, Accuracy: 77.5%\n",
      "[Train] Epoch  13/30, Loss: 0.4408332\n",
      "[Valid] Epoch  13/30, Loss: 0.7289463, Accuracy: 76.2%\n",
      "[Train] Epoch  14/30, Loss: 0.3833914\n",
      "[Valid] Epoch  14/30, Loss: 0.6750470, Accuracy: 78.0%\n",
      "[Train] Epoch  15/30, Loss: 0.3356344\n",
      "[Valid] Epoch  15/30, Loss: 0.6609095, Accuracy: 79.5%\n",
      "[Train] Epoch  16/30, Loss: 0.2887644\n",
      "[Valid] Epoch  16/30, Loss: 0.6988074, Accuracy: 79.3%\n",
      "[Train] Epoch  17/30, Loss: 0.2505597\n",
      "[Valid] Epoch  17/30, Loss: 0.7245480, Accuracy: 78.9%\n",
      "[Train] Epoch  18/30, Loss: 0.2142498\n",
      "[Valid] Epoch  18/30, Loss: 0.7353320, Accuracy: 80.2%\n",
      "[Train] Epoch  19/30, Loss: 0.1792445\n",
      "[Valid] Epoch  19/30, Loss: 0.8618536, Accuracy: 80.0%\n",
      "[Train] Epoch  20/30, Loss: 0.1577809\n",
      "[Valid] Epoch  20/30, Loss: 0.8519002, Accuracy: 79.3%\n",
      "[Train] Epoch  21/30, Loss: 0.1436806\n",
      "[Valid] Epoch  21/30, Loss: 0.7954566, Accuracy: 80.2%\n",
      "[Train] Epoch  22/30, Loss: 0.1259606\n",
      "[Valid] Epoch  22/30, Loss: 0.8036450, Accuracy: 81.0%\n",
      "[Train] Epoch  23/30, Loss: 0.1099280\n",
      "[Valid] Epoch  23/30, Loss: 0.8552545, Accuracy: 81.1%\n",
      "[Train] Epoch  24/30, Loss: 0.1034695\n",
      "[Valid] Epoch  24/30, Loss: 0.8340643, Accuracy: 79.9%\n",
      "[Train] Epoch  25/30, Loss: 0.0807813\n",
      "[Valid] Epoch  25/30, Loss: 0.8736700, Accuracy: 80.2%\n",
      "[Train] Epoch  26/30, Loss: 0.0884184\n",
      "[Valid] Epoch  26/30, Loss: 0.8067667, Accuracy: 80.7%\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0000e-04.\n",
      "[Train] Epoch  27/30, Loss: 0.0214480\n",
      "[Valid] Epoch  27/30, Loss: 0.9548091, Accuracy: 81.7%\n",
      "[Train] Epoch  28/30, Loss: 0.0052431\n",
      "[Valid] Epoch  28/30, Loss: 1.0532718, Accuracy: 81.9%\n",
      "[Train] Epoch  29/30, Loss: 0.0036567\n",
      "[Valid] Epoch  29/30, Loss: 1.1032796, Accuracy: 82.2%\n",
      "[Train] Epoch  30/30, Loss: 0.0024469\n",
      "[Valid] Epoch  30/30, Loss: 1.1304599, Accuracy: 82.1%\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    running_loss = 0.0\n",
    "    vgg16.train() # training mode for dropout\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running_loss += loss.item()\n",
    "        # # print every 30 mini-batches\n",
    "        # if i % 30 == 29:\n",
    "        #     print('[Train] Epoch %3d, Mini-batches %5d, Loss: %.7f' %\n",
    "        #           (epoch+1, i+1, running_loss / 30))\n",
    "        #     running_loss = 0.0\n",
    "        running_loss += loss / len(train_loader)\n",
    "\n",
    "    print('[Train] Epoch %3d/%d, Loss: %.7f' % (epoch+1, epochs, running_loss))\n",
    "    \n",
    "    # Validation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        vgg16.eval() # evaluation mode for dropout\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = vgg16(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss / len(valid_loader)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        print('[Valid] Epoch %3d/%d, Loss: %.7f, Accuracy: %.1f%%' % \n",
    "              (epoch+1, epochs, val_loss, (100*correct / total))\n",
    "            )\n",
    "        \n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797987,
     "status": "ok",
     "timestamp": 1593770270672,
     "user": {
      "displayName": "이영석",
      "photoUrl": "",
      "userId": "08965558652279410114"
     },
     "user_tz": -540
    },
    "id": "1UEDDf4ylrWf",
    "outputId": "4da0ae64-6013-4918-e635-a7268aa62c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.1 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    vgg16.eval() # evaluation mode for dropout\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = vgg16(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.1f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNS6mhHUC0zrrimm1sFL9HU",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
